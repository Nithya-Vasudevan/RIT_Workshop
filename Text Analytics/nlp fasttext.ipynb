{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow as tf\n",
    "import tokenization\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Activation, BatchNormalization, LSTM, Input, Embedding, Layer\n",
    "import keras.backend as K\n",
    "from gensim.models import FastText\n",
    "from keras.callbacks import EarlyStopping\n",
    "import re\n",
    "#from tensorflow.python.client import device_lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning(phrase):\n",
    "    phrase = phrase.lower()\n",
    "    phrase = re.sub(r'http\\S+', '', phrase)\n",
    "    phrase = re.sub('\\W+',' ', phrase).strip()\n",
    "    return phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"train.csv\")\n",
    "data['text_cleaned'] = data.text.apply(cleaning)\n",
    "test = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>text_cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "      <td>our deeds are the reason of this earthquake ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "      <td>forest fire near la ronge sask canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "      <td>all residents asked to shelter in place are be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "      <td>13 000 people receive wildfires evacuation ord...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "      <td>just got sent this photo from ruby alaska as s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target                                       text_cleaned  \n",
       "0       1  our deeds are the reason of this earthquake ma...  \n",
       "1       1              forest fire near la ronge sask canada  \n",
       "2       1  all residents asked to shelter in place are be...  \n",
       "3       1  13 000 people receive wildfires evacuation ord...  \n",
       "4       1  just got sent this photo from ruby alaska as s...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = list(data['text_cleaned'])\n",
    "labels = data.target.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 15.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "vector_dim = 100\n",
    "model_ted = FastText(text, size=vector_dim, window=5, min_count=5, workers=4, sg=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-3.39690538e-04,  6.79267978e-05,  6.84338884e-05, -6.34481985e-05,\n",
       "       -5.79503772e-04,  2.53431004e-04, -1.76215341e-04,  2.00925380e-04,\n",
       "        9.76415467e-05, -3.51795839e-04,  1.36552990e-05,  2.89671530e-04,\n",
       "       -3.95488867e-04,  2.28013174e-04, -7.60009425e-05, -2.05489996e-04,\n",
       "       -9.91586057e-05,  6.88657688e-04, -2.34601408e-04, -2.29328827e-04,\n",
       "        6.41756400e-04,  1.02123758e-03,  6.84470346e-04, -5.82127832e-04,\n",
       "       -1.97119982e-04, -7.36686488e-05,  3.16566555e-04, -1.69533043e-04,\n",
       "       -3.06020287e-04,  3.89121647e-04, -2.13850260e-04,  1.53521760e-04,\n",
       "        6.09358867e-05, -9.42366489e-04, -9.60823891e-05, -1.02146005e-04,\n",
       "        2.26178279e-04, -2.22261384e-04, -1.62984274e-04, -7.70640501e-04,\n",
       "       -8.38334032e-04, -2.42476686e-04,  2.74732331e-04, -1.94297711e-04,\n",
       "        1.69602681e-05, -3.95903859e-04,  8.83301909e-05, -1.89323226e-04,\n",
       "       -3.57702142e-04,  1.04668718e-04,  7.64888769e-04, -2.16367494e-04,\n",
       "       -3.22480861e-04,  7.34639936e-04, -2.04752083e-04, -9.07609210e-05,\n",
       "        3.28692724e-04, -8.95199482e-04, -4.06595427e-05, -3.29962408e-04,\n",
       "       -2.27717013e-04, -1.24672690e-04,  1.13322574e-03, -4.65073936e-05,\n",
       "       -1.75782785e-04, -4.48066567e-04, -9.86896222e-04,  8.06665867e-06,\n",
       "        2.94088677e-04, -6.82045764e-04, -2.35013926e-04, -3.31960240e-04,\n",
       "        1.16288298e-04, -2.69071432e-04,  3.83156148e-05,  2.95687467e-04,\n",
       "        2.64903269e-04,  1.29814391e-04,  3.61444894e-04, -2.55604828e-04,\n",
       "       -9.90747212e-05, -6.10451098e-04,  4.77486856e-06,  5.99392079e-05,\n",
       "       -2.79305008e-04, -5.24428382e-04, -1.69611420e-04, -1.10679182e-04,\n",
       "       -7.30191323e-06,  4.73905588e-04, -7.88465259e-04, -3.63231753e-04,\n",
       "       -5.07198100e-04, -2.75075639e-04,  2.30465273e-04,  7.04217541e-07,\n",
       "        2.39328903e-04,  6.07184593e-05, -5.69563475e-04,  4.76891320e-04],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_ted.wv.word_vec(\"I'm on top of the hill and I can see a fire in the woods...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "VOCAB_SIZE = len(text)\n",
    "EMBEDDING_DIM = vector_dim\n",
    "w2v = np.zeros((VOCAB_SIZE, EMBEDDING_DIM))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\acer\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 5.86 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "FOLDER_PATH = \"D:/tweets\"\n",
    "tsv_file_path = FOLDER_PATH+\"/tensorboard/metadata.tsv\"\n",
    "with open(tsv_file_path,'w+', encoding='utf-8') as file_metadata:\n",
    "    for i,word in enumerate(text):\n",
    "        w2v[i] = model_ted[word]\n",
    "        file_metadata.write(word+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.contrib.tensorboard.plugins import projector\n",
    "TENSORBOARD_FILES_PATH = FOLDER_PATH+\"/tensorboard\"\n",
    "\n",
    "X_init = tf.placeholder(tf.float32, shape=(VOCAB_SIZE, EMBEDDING_DIM), name=\"embedding\")\n",
    "X = tf.Variable(X_init)\n",
    "#Initializer\n",
    "init = tf.global_variables_initializer()\n",
    "#Start Tensorflow Session\n",
    "sess = tf.Session()\n",
    "sess.run(init, feed_dict={X_init: w2v})\n",
    "#Instance of Saver, save the graph.\n",
    "saver = tf.train.Saver()\n",
    "writer = tf.summary.FileWriter(TENSORBOARD_FILES_PATH, sess.graph)\n",
    "\n",
    "#Configure a Tensorflow Projector\n",
    "config = projector.ProjectorConfig()\n",
    "embed = config.embeddings.add()\n",
    "embed.metadata_path = tsv_file_path\n",
    "#Write a projector_config\n",
    "projector.visualize_embeddings(writer,config)\n",
    "#save a checkpoint\n",
    "saver.save(sess, TENSORBOARD_FILES_PATH+'/model.ckpt', global_step = VOCAB_SIZE)\n",
    "#close the session\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#python -m tensorboard.main --logdir=D:/tweets/tensorboard --host=127.0.0.1 --port=6006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = w2v.reshape(7613,100,1)\n",
    "y = data.target.values\n",
    "y = y.reshape(7613,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(x, y, test_size = 0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs1=Input(shape=(100,1))\n",
    "#x1=LSTM(64,return_sequences=True,dropout=0.3,recurrent_dropout=0.2)(inputs1)\n",
    "#att_out=attention()(x1)\n",
    "x1=LSTM(128, dropout=0.3, recurrent_dropout=0.2)(inputs1)\n",
    "#att_out=attention()(x1)\n",
    "x2 = Dense(640,activation='relu')(x1)\n",
    "x2 = Dropout(0.1)(x2)\n",
    "x2 = BatchNormalization()(x2)\n",
    "x2 = Dense(320,activation='relu')(x2)\n",
    "x2 = Dropout(0.1)(x2)\n",
    "x2 = BatchNormalization()(x2)\n",
    "x2 = Dense(128,activation='relu')(x2)\n",
    "x2 = Dropout(0.1)(x2)\n",
    "x2 = BatchNormalization()(x2)\n",
    "x2 = Dense(64,activation='relu')(x2)\n",
    "x2 = Dropout(0.1)(x2)\n",
    "x2 = BatchNormalization()(x2)\n",
    "x2 = Dense(32,activation='relu')(x2)\n",
    "x2 = Dropout(0.1)(x2)\n",
    "x2 = BatchNormalization()(x2)\n",
    "x2 = Dense(16,activation='relu')(x2)\n",
    "x2 = Dropout(0.1)(x2)\n",
    "x2 = BatchNormalization()(x2)\n",
    "x2 = Dense(8,activation='relu')(x2)\n",
    "outputs1=Dense(1,activation='sigmoid')(x2)\n",
    "model1=Model(inputs1,outputs1)\n",
    "model1.compile(loss = 'binary_crossentropy', optimizer='Adam',metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         (None, 100, 1)            0         \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 128)               66560     \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 640)               82560     \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 640)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_19 (Batc (None, 640)               2560      \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 320)               205120    \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 320)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_20 (Batc (None, 320)               1280      \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 128)               41088     \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_21 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout_22 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_22 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dropout_23 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_23 (Batc (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dropout_24 (Dropout)         (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_24 (Batc (None, 16)                64        \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 411,137\n",
      "Trainable params: 408,737\n",
      "Non-trainable params: 2,400\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5709 samples, validate on 1904 samples\n",
      "Epoch 1/20\n",
      "5709/5709 [==============================] - 12s 2ms/step - loss: 0.7937 - acc: 0.5435 - val_loss: 1.3623 - val_acc: 0.4202\n",
      "Epoch 2/20\n",
      "5709/5709 [==============================] - 4s 665us/step - loss: 0.7646 - acc: 0.5388 - val_loss: 0.6908 - val_acc: 0.5641\n",
      "Epoch 3/20\n",
      "5709/5709 [==============================] - 4s 665us/step - loss: 0.7516 - acc: 0.5525 - val_loss: 0.6842 - val_acc: 0.5798\n",
      "Epoch 4/20\n",
      "5709/5709 [==============================] - 4s 662us/step - loss: 0.7423 - acc: 0.5493 - val_loss: 0.6819 - val_acc: 0.5798\n",
      "Epoch 5/20\n",
      "5709/5709 [==============================] - 4s 670us/step - loss: 0.7284 - acc: 0.5519 - val_loss: 0.6804 - val_acc: 0.5798\n",
      "Epoch 6/20\n",
      "5709/5709 [==============================] - 4s 667us/step - loss: 0.7226 - acc: 0.5404 - val_loss: 0.6808 - val_acc: 0.5798\n",
      "Epoch 7/20\n",
      "5709/5709 [==============================] - 4s 662us/step - loss: 0.7109 - acc: 0.5523 - val_loss: 0.6886 - val_acc: 0.5798\n",
      "Epoch 8/20\n",
      "5709/5709 [==============================] - 4s 674us/step - loss: 0.7183 - acc: 0.5388 - val_loss: 0.6814 - val_acc: 0.5798\n",
      "Epoch 9/20\n",
      "5709/5709 [==============================] - 4s 686us/step - loss: 0.7089 - acc: 0.5455 - val_loss: 0.6805 - val_acc: 0.5798\n",
      "Epoch 10/20\n",
      "5709/5709 [==============================] - 4s 699us/step - loss: 0.7063 - acc: 0.5465 - val_loss: 0.6836 - val_acc: 0.5798\n",
      "Epoch 11/20\n",
      "5709/5709 [==============================] - 4s 671us/step - loss: 0.7031 - acc: 0.5434 - val_loss: 0.6857 - val_acc: 0.5798\n",
      "Epoch 12/20\n",
      "5709/5709 [==============================] - 4s 654us/step - loss: 0.7017 - acc: 0.5446 - val_loss: 0.6828 - val_acc: 0.5798\n",
      "Epoch 13/20\n",
      "5709/5709 [==============================] - 4s 711us/step - loss: 0.7025 - acc: 0.5400 - val_loss: 0.6852 - val_acc: 0.5798\n",
      "Epoch 14/20\n",
      "5709/5709 [==============================] - 4s 682us/step - loss: 0.7007 - acc: 0.5490 - val_loss: 0.6921 - val_acc: 0.5798\n",
      "Epoch 15/20\n",
      "5709/5709 [==============================] - 4s 774us/step - loss: 0.6951 - acc: 0.5453 - val_loss: 0.6960 - val_acc: 0.5798\n",
      "Epoch 16/20\n",
      "5709/5709 [==============================] - 4s 708us/step - loss: 0.7008 - acc: 0.5505 - val_loss: 0.6812 - val_acc: 0.5798\n",
      "Epoch 17/20\n",
      "5709/5709 [==============================] - 4s 678us/step - loss: 0.6973 - acc: 0.5344 - val_loss: 0.6819 - val_acc: 0.5798\n",
      "Epoch 18/20\n",
      "5709/5709 [==============================] - 4s 666us/step - loss: 0.6982 - acc: 0.5477 - val_loss: 0.6812 - val_acc: 0.5798\n",
      "Epoch 19/20\n",
      "5709/5709 [==============================] - 4s 669us/step - loss: 0.6945 - acc: 0.5467 - val_loss: 0.6804 - val_acc: 0.5798\n",
      "Epoch 20/20\n",
      "5709/5709 [==============================] - 4s 685us/step - loss: 0.6986 - acc: 0.5498 - val_loss: 0.6867 - val_acc: 0.5798\n"
     ]
    }
   ],
   "source": [
    "history = model1.fit(X_train, y_train, epochs= 20, shuffle = True, validation_data=[X_test,y_test], batch_size=1000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
